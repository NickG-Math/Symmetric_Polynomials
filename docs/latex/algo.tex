\hypertarget{algo_smith}{}\doxysection{Smith Normal Form}\label{algo_smith}
There are multiple ways to compute the Smith Normal Form of a matrix, but since we are mostly interested in the coefficient matrices, we employ the row/column elimination algorithm. To use the algorithm we need to be able to choose a pivot for our matrix each time we want to clear a row and column. We have the freedom to choose it and there are (at least) three ways to do it\+:


\begin{DoxyItemize}
\item Use the first nonzero element as pivot, and if a smaller nonzero element (in absolute value) appears during the elimination then switch to that.
\item Use the minimum (in absolute value) nonzero elemenent as pivot. If there are multiple choices, pick the first one as we iterate through the matrix.
\item As above, but instead of picking the first minimum, choose it so that it minimizes a certain norm function.
\end{DoxyItemize}

This norm function, called a Markowitz metric, can be for example $N(i,j)=|\{a_{is}\neq 0: s\}| + |a_{sj}\neq 0:s|$

One reason we are considering multiple pivoting choices is coefficient explosion\+: Even if the entries of the matrix are small ( $\pm 1$), the entries of the Smith Normal Form (and especially those of the coefficient matrices) can easily overflow if we make the wrong choice of pivot. You can read more about this problem in \href{https://arxiv.org/abs/math/9406205}{\texttt{ Recognizing badly presented Z modules}}.

Of the three choices above, the first is most likely to result to overflow, but is usually the fastest when it doesn\textquotesingle{}t. The second is a great option for smaller matrices ($<$1000 rows and columns) while the third excells with very big matrices.

But there is another reason to use the third option, and that\textquotesingle{}s sparse matrices.

When our matrices get large (7000 rows and columns) they are also very sparse (99.\+9\% entries being 0) so we can make huge savings on memory (and potentially computational time) by using a sparse matrix format that only records the nonzero values.

The usage of sparse matrices necessitates great care or performance will suffer\+: For example, insertions of nonzero elements and random access do not have constant complexity.

As far as the Smith normal form is concerned, to have good performance with sparse matrices we need to minimize fill-\/in, which is the creation of nonzero elements from adding a row/column to another one. The Markowitz metric described above is used to very roughtly estimate the fill-\/in that we would get if the given element was used as pivot. There are many other choices as explained \href{https://arxiv.org/abs/math/9406205}{\texttt{ here}}.

Thus in total we have 4 Smith implementations\+:


\begin{DoxyItemize}
\item {\ttfamily Mackey\+::\+Smith\+FP} using the first nonzero element as pivot. Called in the dense finite coefficient case.
\item {\ttfamily Mackey\+::\+Smith\+MP} using the minimum (in absolute value) nonzero elemenent as pivot (first instance). Called for dense matrices with at most 1000 rows and columns.
\item {\ttfamily Mackey\+::\+Smith\+SP} using the instance of the minimum that also minimizes a norm function. Called for dense matrices with above 1000 rows and columns.
\item {\ttfamily Mackey\+::\+Smith\+Sparse} which is the same as {\ttfamily Mackey\+::\+Smith\+SP} but using sparse matrices. Called for sparse matrices.
\end{DoxyItemize}\hypertarget{algo_cob}{}\doxysection{Change of Basis}\label{algo_cob}
If we have bases for modules $A,B$ then $A\otimes B$ can be canonically given two lexicographical bases, that we call left and right convenient bases. But if $A,B$ are the bottom levels of free Mackey functors then they have equivariant bases and the tensor product also gets an equivariant basis, called the canonical one. The left and right convenient bases are used to write the left and right differentials in a simple manner (hence their designation as convenient). The canonical bases are used to transfer. To get the change of basis matrix, we are reduced to computing the permutation $a^{-1}b$ where $a,b$ are two permutations of the same set.\hypertarget{algo_box}{}\doxysection{Box product}\label{algo_box}
Computing the tensor product of Chain complexes breaks down to computing the left and right differentials $L(x\otimes y)=dx\otimes y$ and $R(x\otimes y)=(-1)^{|x|}x\otimes dy$ respectively. If we use the convenient bases explained in the previous section, these are just block diagonal matrices with the blocks being the differential from the original chains $d$. To get $L,R$ w.\+r.\+t. the canonical bases, we need to apply the change of basis matrices. Once we do that the total differential of the tensor product is just $L+R$. To be more accurate, $L$ is not a single differential, but rather a sequence of them, one for each summand of the Box product; $(C\otimes D)_n\to (C\otimes D)_{n-1}$ is a map $C_n\otimes D_0\oplus\cdots \oplus C_0\otimes D_n\to C_0\otimes D_{n-1}\oplus\cdots\oplus C_{n-1}\otimes D_0$. Each summand of this map is computed separately into an $L$ and an $R$, and then these are mixed together to form the total differential. The mixing specifies that we start with a block $ L_0$, then place $ R_0$ directly below it, then $L_1$ adjecent to the right of $ R_0$ etc.\hypertarget{algo_graph}{}\doxysection{Graphs}\label{algo_graph}

\begin{DoxyItemize}
\item For weighted graphs we want the shortest path from a given source to all other points. I use a straightforward implementation of Dikjstra\textquotesingle{}s algorithm using std\+::priority\+\_\+queue.
\item For graphs of two colors, we are interested in the paths from the source to all points with the minimum numer of alternating colors (an alternation of colors means switching from division to multiplication and vice-\/versa). This problem can be easily reduced to finding the shortest path for weighted graphs, by using a sort of \char`\"{}dual\char`\"{} graph where now the nodes are colored and the now monochrome edges between same colored nodes have weight 0, while for different colored nodes we get weight 1. To get the new graph simply duplicate the nodes of the original, color the originals by red and the new ones by blue, and quadruple the edges (so we using all combinations of colored nodes) and set the weights as I just explained. After that, find the red and blue paths starting from a red/blue source and ending to each point, compare them in length and choose the shortest one. 
\end{DoxyItemize}